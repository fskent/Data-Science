{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".h1_cell, .just_text {\n",
       "    box-sizing: border-box;\n",
       "    padding-top:5px;\n",
       "    padding-bottom:5px;\n",
       "    font-family: \"Times New Roman\", Georgia, Serif;\n",
       "    font-size: 125%;\n",
       "    line-height: 22px; /* 5px +12px + 5px */\n",
       "    text-indent: 25px;\n",
       "    background-color: #fbfbea;\n",
       "    padding: 10px;\n",
       "    border-style: groove;\n",
       "}\n",
       "\n",
       "hr { \n",
       "    display: block;\n",
       "    margin-top: 0.5em;\n",
       "    margin-bottom: 0.5em;\n",
       "    margin-left: au                              to;\n",
       "    margin-right: auto;\n",
       "    border-style: inset;\n",
       "    border-width: 2px;\n",
       "}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    ".h1_cell, .just_text {\n",
    "    box-sizing: border-box;\n",
    "    padding-top:5px;\n",
    "    padding-bottom:5px;\n",
    "    font-family: \"Times New Roman\", Georgia, Serif;\n",
    "    font-size: 125%;\n",
    "    line-height: 22px; /* 5px +12px + 5px */\n",
    "    text-indent: 25px;\n",
    "    background-color: #fbfbea;\n",
    "    padding: 10px;\n",
    "    border-style: groove;\n",
    "}\n",
    "\n",
    "hr { \n",
    "    display: block;\n",
    "    margin-top: 0.5em;\n",
    "    margin-bottom: 0.5em;\n",
    "    margin-left: au                              to;\n",
    "    margin-right: auto;\n",
    "    border-style: inset;\n",
    "    border-width: 2px;\n",
    "}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>\n",
    "<center>\n",
    "Module 7 - A panel of experts\n",
    "</center>\n",
    "</h1>\n",
    "<div class=h1_cell>\n",
    "<p>\n",
    "This is the last module where we will be treating words as numbers, in essence, vectorizing words. I want to leave this part of the course with a bang so I decided to look at a real problem. We will be back to doing prediction. The problem is that the site donorschoose.org is overwhelmed with applications. You can read the details at https://www.kaggle.com/c/donorschoose-application-screening (yes, this is a Kaggle competition). Briefly, teachers apply for funding to help them further their classroom teaching. The application has a number of boxes for a teacher to fill in. We will concentrate on just three: the first essay they must write, the second essay they must write and the title of their project. Our target column is 'project_is_funded', a binary column with 0 meaning their application was rejected.\n",
    "<p>\n",
    "I am going to add a bit of a twist this week. I am going to ask you to use what is called an *ensemble* approach. At its broadest, this ia a machine learning term meaning you will use a number of models/methods to make a prediction. They are the ensemble. They reach a prediction by simple voting. They can be all the same methods (like we will use) or different methods (e.g., mixture of NB and KNN). Ensemble methods have had huge success in machine learning in general so I decided to try it here. Below is the general idea:\n",
    "<ul>\n",
    "<li> For essay 1, use NB using only essay 1 words.\n",
    "<li> For essay 2, use NB using only essay 2 words.\n",
    "<li> For the title, use NB using only title words.\n",
    "</ul>\n",
    "<p>\n",
    "That is our motley ensemble. Each NB method specializes in one of the columns, They will each reach a prediction then vote.\n",
    "<p>\n",
    "Note: you will not really create three separate NB functions. You will simply call your one NB function with different parameters.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>\n",
    "What you will need\n",
    "</h2>\n",
    "<div class=h1_cell>\n",
    "<p>\n",
    "You will need the following functions from past modules:\n",
    "<ul>\n",
    "<li> sentence_wrangler and its helpers.\n",
    "<li> naive_bayes using cosine_similarity\n",
    "</ul>\n",
    "<p>\n",
    "You will also need patience given that we will be using 180K separate teacher-applications.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-b297181ddb06>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'https://www.dropbox.com/s/2hdbltrl8bh6kbu/train.csv?raw=1'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdonate_table\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/stevekent/anaconda2/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    707\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 709\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    710\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/stevekent/anaconda2/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    431\u001b[0m     \u001b[0mcompression\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_infer_compression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m     filepath_or_buffer, _, compression = get_filepath_or_buffer(\n\u001b[0;32m--> 433\u001b[0;31m         filepath_or_buffer, encoding, compression)\n\u001b[0m\u001b[1;32m    434\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'compression'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/stevekent/anaconda2/lib/python2.7/site-packages/pandas/io/common.pyc\u001b[0m in \u001b[0;36mget_filepath_or_buffer\u001b[0;34m(filepath_or_buffer, encoding, compression)\u001b[0m\n\u001b[1;32m    193\u001b[0m             \u001b[0;31m# Override compression based on Content-Encoding header\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m             \u001b[0mcompression\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'gzip'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mreader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/stevekent/anaconda2/lib/python2.7/socket.pyc\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    353\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m                     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrbufsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mEINTR\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/stevekent/anaconda2/lib/python2.7/httplib.pyc\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    595\u001b[0m         \u001b[0;31m# connection, and the user is reading more bytes than will be provided\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m         \u001b[0;31m# (for example, reading in 1k chunks)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 597\u001b[0;31m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    598\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mamt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m             \u001b[0;31m# Ideally, we would raise IncompleteRead if the content-length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/stevekent/anaconda2/lib/python2.7/socket.pyc\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    382\u001b[0m                 \u001b[0;31m# fragmentation issues on many platforms.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m                     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mEINTR\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/stevekent/anaconda2/lib/python2.7/ssl.pyc\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, buflen, flags)\u001b[0m\n\u001b[1;32m    764\u001b[0m                     \u001b[0;34m\"non-zero flags not allowed in calls to recv() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m                     self.__class__)\n\u001b[0;32m--> 766\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuflen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    767\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuflen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/stevekent/anaconda2/lib/python2.7/ssl.pyc\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m    651\u001b[0m                 \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    652\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 653\u001b[0;31m                 \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    654\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    655\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mSSLError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "url = 'https://www.dropbox.com/s/2hdbltrl8bh6kbu/train.csv?raw=1'\n",
    "donate_table = pd.read_csv(url, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>teacher_id</th>\n",
       "      <th>teacher_prefix</th>\n",
       "      <th>school_state</th>\n",
       "      <th>project_submitted_datetime</th>\n",
       "      <th>project_grade_category</th>\n",
       "      <th>project_subject_categories</th>\n",
       "      <th>project_subject_subcategories</th>\n",
       "      <th>project_title</th>\n",
       "      <th>project_essay_1</th>\n",
       "      <th>project_essay_2</th>\n",
       "      <th>project_essay_3</th>\n",
       "      <th>project_essay_4</th>\n",
       "      <th>project_resource_summary</th>\n",
       "      <th>teacher_number_of_previously_posted_projects</th>\n",
       "      <th>project_is_approved</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p036502</td>\n",
       "      <td>484aaf11257089a66cfedc9461c6bd0a</td>\n",
       "      <td>Ms.</td>\n",
       "      <td>NV</td>\n",
       "      <td>2016-11-18 14:45:59</td>\n",
       "      <td>Grades PreK-2</td>\n",
       "      <td>Literacy &amp; Language</td>\n",
       "      <td>Literacy</td>\n",
       "      <td>Super Sight Word Centers</td>\n",
       "      <td>Most of my kindergarten students come from low...</td>\n",
       "      <td>I currently have a differentiated sight word c...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>My students need 6 Ipod Nano's to create and d...</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p039565</td>\n",
       "      <td>df72a3ba8089423fa8a94be88060f6ed</td>\n",
       "      <td>Mrs.</td>\n",
       "      <td>GA</td>\n",
       "      <td>2017-04-26 15:57:28</td>\n",
       "      <td>Grades 3-5</td>\n",
       "      <td>Music &amp; The Arts, Health &amp; Sports</td>\n",
       "      <td>Performing Arts, Team Sports</td>\n",
       "      <td>Keep Calm and Dance On</td>\n",
       "      <td>Our elementary school is a culturally rich sch...</td>\n",
       "      <td>We strive to provide our diverse population of...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>My students need matching shirts to wear for d...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p233823</td>\n",
       "      <td>a9b876a9252e08a55e3d894150f75ba3</td>\n",
       "      <td>Ms.</td>\n",
       "      <td>UT</td>\n",
       "      <td>2017-01-01 22:57:44</td>\n",
       "      <td>Grades 3-5</td>\n",
       "      <td>Math &amp; Science, Literacy &amp; Language</td>\n",
       "      <td>Applied Sciences, Literature &amp; Writing</td>\n",
       "      <td>Lets 3Doodle to Learn</td>\n",
       "      <td>Hello;\\r\\nMy name is Mrs. Brotherton. I teach ...</td>\n",
       "      <td>We are looking to add some 3Doodler to our cla...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>My students need the 3doodler. We are an SEM s...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p185307</td>\n",
       "      <td>525fdbb6ec7f538a48beebaa0a51b24f</td>\n",
       "      <td>Mr.</td>\n",
       "      <td>NC</td>\n",
       "      <td>2016-08-12 15:42:11</td>\n",
       "      <td>Grades 3-5</td>\n",
       "      <td>Health &amp; Sports</td>\n",
       "      <td>Health &amp; Wellness</td>\n",
       "      <td>\\\"Kid Inspired\\\" Equipment to Increase Activit...</td>\n",
       "      <td>My students are the greatest students but are ...</td>\n",
       "      <td>The student's project which is totally \\\"kid-i...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>My students need balls and other activity equi...</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p013780</td>\n",
       "      <td>a63b5547a7239eae4c1872670848e61a</td>\n",
       "      <td>Mr.</td>\n",
       "      <td>CA</td>\n",
       "      <td>2016-08-06 09:09:11</td>\n",
       "      <td>Grades 6-8</td>\n",
       "      <td>Health &amp; Sports</td>\n",
       "      <td>Health &amp; Wellness</td>\n",
       "      <td>We need clean water for our culinary arts class!</td>\n",
       "      <td>My students are athletes and students who are ...</td>\n",
       "      <td>For some reason in our kitchen the water comes...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>My students need a water filtration system for...</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                        teacher_id teacher_prefix school_state  \\\n",
       "0  p036502  484aaf11257089a66cfedc9461c6bd0a            Ms.           NV   \n",
       "1  p039565  df72a3ba8089423fa8a94be88060f6ed           Mrs.           GA   \n",
       "2  p233823  a9b876a9252e08a55e3d894150f75ba3            Ms.           UT   \n",
       "3  p185307  525fdbb6ec7f538a48beebaa0a51b24f            Mr.           NC   \n",
       "4  p013780  a63b5547a7239eae4c1872670848e61a            Mr.           CA   \n",
       "\n",
       "  project_submitted_datetime project_grade_category  \\\n",
       "0        2016-11-18 14:45:59          Grades PreK-2   \n",
       "1        2017-04-26 15:57:28             Grades 3-5   \n",
       "2        2017-01-01 22:57:44             Grades 3-5   \n",
       "3        2016-08-12 15:42:11             Grades 3-5   \n",
       "4        2016-08-06 09:09:11             Grades 6-8   \n",
       "\n",
       "            project_subject_categories  \\\n",
       "0                  Literacy & Language   \n",
       "1    Music & The Arts, Health & Sports   \n",
       "2  Math & Science, Literacy & Language   \n",
       "3                      Health & Sports   \n",
       "4                      Health & Sports   \n",
       "\n",
       "            project_subject_subcategories  \\\n",
       "0                                Literacy   \n",
       "1            Performing Arts, Team Sports   \n",
       "2  Applied Sciences, Literature & Writing   \n",
       "3                       Health & Wellness   \n",
       "4                       Health & Wellness   \n",
       "\n",
       "                                       project_title  \\\n",
       "0                           Super Sight Word Centers   \n",
       "1                             Keep Calm and Dance On   \n",
       "2                              Lets 3Doodle to Learn   \n",
       "3  \\\"Kid Inspired\\\" Equipment to Increase Activit...   \n",
       "4   We need clean water for our culinary arts class!   \n",
       "\n",
       "                                     project_essay_1  \\\n",
       "0  Most of my kindergarten students come from low...   \n",
       "1  Our elementary school is a culturally rich sch...   \n",
       "2  Hello;\\r\\nMy name is Mrs. Brotherton. I teach ...   \n",
       "3  My students are the greatest students but are ...   \n",
       "4  My students are athletes and students who are ...   \n",
       "\n",
       "                                     project_essay_2 project_essay_3  \\\n",
       "0  I currently have a differentiated sight word c...             NaN   \n",
       "1  We strive to provide our diverse population of...             NaN   \n",
       "2  We are looking to add some 3Doodler to our cla...             NaN   \n",
       "3  The student's project which is totally \\\"kid-i...             NaN   \n",
       "4  For some reason in our kitchen the water comes...             NaN   \n",
       "\n",
       "  project_essay_4                           project_resource_summary  \\\n",
       "0             NaN  My students need 6 Ipod Nano's to create and d...   \n",
       "1             NaN  My students need matching shirts to wear for d...   \n",
       "2             NaN  My students need the 3doodler. We are an SEM s...   \n",
       "3             NaN  My students need balls and other activity equi...   \n",
       "4             NaN  My students need a water filtration system for...   \n",
       "\n",
       "   teacher_number_of_previously_posted_projects  project_is_approved  \n",
       "0                                            26                    1  \n",
       "1                                             1                    0  \n",
       "2                                             5                    1  \n",
       "3                                            16                    0  \n",
       "4                                            42                    1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "donate_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>teacher_id</th>\n",
       "      <th>teacher_prefix</th>\n",
       "      <th>school_state</th>\n",
       "      <th>project_submitted_datetime</th>\n",
       "      <th>project_grade_category</th>\n",
       "      <th>project_subject_categories</th>\n",
       "      <th>project_subject_subcategories</th>\n",
       "      <th>project_title</th>\n",
       "      <th>project_essay_1</th>\n",
       "      <th>project_essay_2</th>\n",
       "      <th>project_essay_3</th>\n",
       "      <th>project_essay_4</th>\n",
       "      <th>project_resource_summary</th>\n",
       "      <th>teacher_number_of_previously_posted_projects</th>\n",
       "      <th>project_is_approved</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>182080</td>\n",
       "      <td>182080</td>\n",
       "      <td>182076</td>\n",
       "      <td>182080</td>\n",
       "      <td>182080</td>\n",
       "      <td>182080</td>\n",
       "      <td>182080</td>\n",
       "      <td>182080</td>\n",
       "      <td>182080</td>\n",
       "      <td>182080</td>\n",
       "      <td>182080</td>\n",
       "      <td>6374</td>\n",
       "      <td>6374</td>\n",
       "      <td>182080</td>\n",
       "      <td>182080.000000</td>\n",
       "      <td>182080.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>182080</td>\n",
       "      <td>104414</td>\n",
       "      <td>5</td>\n",
       "      <td>51</td>\n",
       "      <td>180439</td>\n",
       "      <td>4</td>\n",
       "      <td>51</td>\n",
       "      <td>407</td>\n",
       "      <td>164282</td>\n",
       "      <td>147689</td>\n",
       "      <td>180984</td>\n",
       "      <td>6359</td>\n",
       "      <td>6336</td>\n",
       "      <td>179730</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>p009803</td>\n",
       "      <td>fa2f220b537e8653fb48878ebb38044d</td>\n",
       "      <td>Mrs.</td>\n",
       "      <td>CA</td>\n",
       "      <td>2016-09-01 00:00:03</td>\n",
       "      <td>Grades PreK-2</td>\n",
       "      <td>Literacy &amp; Language</td>\n",
       "      <td>Literacy</td>\n",
       "      <td>Flexible Seating</td>\n",
       "      <td>As a teacher in a low-income/high poverty scho...</td>\n",
       "      <td>Students will be using Chromebooks to increase...</td>\n",
       "      <td>My students need to learn how to rhyme, identi...</td>\n",
       "      <td>As a teacher, it is important to show students...</td>\n",
       "      <td>My students need electronic tablets to do all ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>74</td>\n",
       "      <td>95405</td>\n",
       "      <td>25695</td>\n",
       "      <td>30</td>\n",
       "      <td>73890</td>\n",
       "      <td>39257</td>\n",
       "      <td>15775</td>\n",
       "      <td>377</td>\n",
       "      <td>46</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>84</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.237055</td>\n",
       "      <td>0.847682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.016086</td>\n",
       "      <td>0.359330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>451.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                        teacher_id teacher_prefix school_state  \\\n",
       "count    182080                            182080         182076       182080   \n",
       "unique   182080                            104414              5           51   \n",
       "top     p009803  fa2f220b537e8653fb48878ebb38044d           Mrs.           CA   \n",
       "freq          1                                74          95405        25695   \n",
       "mean        NaN                               NaN            NaN          NaN   \n",
       "std         NaN                               NaN            NaN          NaN   \n",
       "min         NaN                               NaN            NaN          NaN   \n",
       "25%         NaN                               NaN            NaN          NaN   \n",
       "50%         NaN                               NaN            NaN          NaN   \n",
       "75%         NaN                               NaN            NaN          NaN   \n",
       "max         NaN                               NaN            NaN          NaN   \n",
       "\n",
       "       project_submitted_datetime project_grade_category  \\\n",
       "count                      182080                 182080   \n",
       "unique                     180439                      4   \n",
       "top           2016-09-01 00:00:03          Grades PreK-2   \n",
       "freq                           30                  73890   \n",
       "mean                          NaN                    NaN   \n",
       "std                           NaN                    NaN   \n",
       "min                           NaN                    NaN   \n",
       "25%                           NaN                    NaN   \n",
       "50%                           NaN                    NaN   \n",
       "75%                           NaN                    NaN   \n",
       "max                           NaN                    NaN   \n",
       "\n",
       "       project_subject_categories project_subject_subcategories  \\\n",
       "count                      182080                        182080   \n",
       "unique                         51                           407   \n",
       "top           Literacy & Language                      Literacy   \n",
       "freq                        39257                         15775   \n",
       "mean                          NaN                           NaN   \n",
       "std                           NaN                           NaN   \n",
       "min                           NaN                           NaN   \n",
       "25%                           NaN                           NaN   \n",
       "50%                           NaN                           NaN   \n",
       "75%                           NaN                           NaN   \n",
       "max                           NaN                           NaN   \n",
       "\n",
       "           project_title                                    project_essay_1  \\\n",
       "count             182080                                             182080   \n",
       "unique            164282                                             147689   \n",
       "top     Flexible Seating  As a teacher in a low-income/high poverty scho...   \n",
       "freq                 377                                                 46   \n",
       "mean                 NaN                                                NaN   \n",
       "std                  NaN                                                NaN   \n",
       "min                  NaN                                                NaN   \n",
       "25%                  NaN                                                NaN   \n",
       "50%                  NaN                                                NaN   \n",
       "75%                  NaN                                                NaN   \n",
       "max                  NaN                                                NaN   \n",
       "\n",
       "                                          project_essay_2  \\\n",
       "count                                              182080   \n",
       "unique                                             180984   \n",
       "top     Students will be using Chromebooks to increase...   \n",
       "freq                                                   24   \n",
       "mean                                                  NaN   \n",
       "std                                                   NaN   \n",
       "min                                                   NaN   \n",
       "25%                                                   NaN   \n",
       "50%                                                   NaN   \n",
       "75%                                                   NaN   \n",
       "max                                                   NaN   \n",
       "\n",
       "                                          project_essay_3  \\\n",
       "count                                                6374   \n",
       "unique                                               6359   \n",
       "top     My students need to learn how to rhyme, identi...   \n",
       "freq                                                    2   \n",
       "mean                                                  NaN   \n",
       "std                                                   NaN   \n",
       "min                                                   NaN   \n",
       "25%                                                   NaN   \n",
       "50%                                                   NaN   \n",
       "75%                                                   NaN   \n",
       "max                                                   NaN   \n",
       "\n",
       "                                          project_essay_4  \\\n",
       "count                                                6374   \n",
       "unique                                               6336   \n",
       "top     As a teacher, it is important to show students...   \n",
       "freq                                                    3   \n",
       "mean                                                  NaN   \n",
       "std                                                   NaN   \n",
       "min                                                   NaN   \n",
       "25%                                                   NaN   \n",
       "50%                                                   NaN   \n",
       "75%                                                   NaN   \n",
       "max                                                   NaN   \n",
       "\n",
       "                                 project_resource_summary  \\\n",
       "count                                              182080   \n",
       "unique                                             179730   \n",
       "top     My students need electronic tablets to do all ...   \n",
       "freq                                                   84   \n",
       "mean                                                  NaN   \n",
       "std                                                   NaN   \n",
       "min                                                   NaN   \n",
       "25%                                                   NaN   \n",
       "50%                                                   NaN   \n",
       "75%                                                   NaN   \n",
       "max                                                   NaN   \n",
       "\n",
       "        teacher_number_of_previously_posted_projects  project_is_approved  \n",
       "count                                  182080.000000        182080.000000  \n",
       "unique                                           NaN                  NaN  \n",
       "top                                              NaN                  NaN  \n",
       "freq                                             NaN                  NaN  \n",
       "mean                                       11.237055             0.847682  \n",
       "std                                        28.016086             0.359330  \n",
       "min                                         0.000000             0.000000  \n",
       "25%                                         0.000000             1.000000  \n",
       "50%                                         2.000000             1.000000  \n",
       "75%                                         9.000000             1.000000  \n",
       "max                                       451.000000             1.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "donate_table.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "182080"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(donate_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'Most of my kindergarten students come from low-income households and are considered \\\\\"at-risk\\\\\". These kids walk to school alongside their parents and most have never been further than walking distance from their house. For 80% of my students, English is not their first language or the language spoken at home. \\\\r\\\\n\\\\r\\\\nWhile my kindergarten kids have many obstacles in front of them, they come to school each day excited and ready to learn. Most students started the year out never being in a school setting. At the start of the year many had never been exposed to letters. Each day they soak up more knowledge and try their hardest to succeed. They are highly motivated to learn new things every day. We are halfway through the year and they are starting to take off. They know know all letters, some sight words, numbers to 20, and a majority of their letter sounds because of their hard work and determination. I am excited to see the places we will go from here!'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row0_essay1 = donate_table.loc[0, 'project_essay_1']\n",
    "row0_essay1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'Most of my kindergarten students come from low-income households and are considered \\\\\"at-risk\\\\\"',\n",
       " u' These kids walk to school alongside their parents and most have never been further than walking distance from their house',\n",
       " u' For 80% of my students, English is not their first language or the language spoken at home',\n",
       " u' \\\\r\\\\n\\\\r\\\\nWhile my kindergarten kids have many obstacles in front of them, they come to school each day excited and ready to learn',\n",
       " u' Most students started the year out never being in a school setting',\n",
       " u' At the start of the year many had never been exposed to letters',\n",
       " u' Each day they soak up more knowledge and try their hardest to succeed',\n",
       " u' They are highly motivated to learn new things every day',\n",
       " u' We are halfway through the year and they are starting to take off',\n",
       " u' They know know all letters, some sight words, numbers to 20, and a majority of their letter sounds because of their hard work and determination',\n",
       " u' I am excited to see the places we will go from here!']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = row0_essay1.split('.')  # I am using a simple split on period\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sentence_wrangler here\n",
    "\n",
    "def sentence_wrangler(sentence, swords, legal_chars):\n",
    "    tokes = word_punct_tokenizer.tokenize(sentence)\n",
    "    result = []\n",
    "    removed = []\n",
    "    check = 0\n",
    "    for word in tokes:\n",
    "        if word.lower() not in swords:\n",
    "            for i in word.lower():\n",
    "                if i in legal_chars:\n",
    "                    check = 1\n",
    "                else: \n",
    "                    check = 0\n",
    "            if check == 1:\n",
    "                result.append(word.lower())\n",
    "            else:\n",
    "                removed.append(word.lower())\n",
    "        else:\n",
    "            removed.append(word.lower())\n",
    "    return (result, removed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stuff need to wrangle here\n",
    "import string\n",
    "punctuation = string.punctuation\n",
    "\n",
    "legals = 'abcdefghijklmnopqrstuvwxyz'\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "swords = stopwords.words('english')\n",
    "\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "word_punct_tokenizer = WordPunctTokenizer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([u'kindergarten',\n",
       "  u'students',\n",
       "  u'come',\n",
       "  u'low',\n",
       "  u'income',\n",
       "  u'households',\n",
       "  u'considered',\n",
       "  u'risk'],\n",
       " [u'most',\n",
       "  u'of',\n",
       "  u'my',\n",
       "  u'from',\n",
       "  u'-',\n",
       "  u'and',\n",
       "  u'are',\n",
       "  u'\\\\\"',\n",
       "  u'at',\n",
       "  u'-',\n",
       "  u'\\\\\"'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_wrangler(sentences[0], swords, legals)  # sentences created above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'Super Sight Word Centers'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title0 = donate_table.loc[0, 'project_title']  # no need to break into sentence\n",
    "title0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([u'super', u'sight', u'word', u'centers'], [])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_wrangler(title0, swords, legals)  # nothing removed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>\n",
    "Generate the bag of words you will need for essay 1, essay 2, and title.\n",
    "</h2>\n",
    "<div class=h1_cell>\n",
    "Remember you need 3 separate bag of words: feed them from the 2 separate essays and the title.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/46\n",
      "2/46\n",
      "3/46\n",
      "4/46\n",
      "5/46\n",
      "6/46\n",
      "7/46\n",
      "8/46\n",
      "9/46\n",
      "10/46\n",
      "11/46\n",
      "12/46\n",
      "13/46\n",
      "14/46\n",
      "15/46\n",
      "16/46\n",
      "17/46\n",
      "18/46\n",
      "19/46\n",
      "20/46\n",
      "21/46\n",
      "22/46\n",
      "23/46\n",
      "24/46\n",
      "25/46\n",
      "26/46\n",
      "27/46\n",
      "28/46\n",
      "29/46\n",
      "30/46\n",
      "31/46\n",
      "32/46\n",
      "33/46\n",
      "34/46\n",
      "35/46\n",
      "36/46\n",
      "37/46\n",
      "38/46\n",
      "39/46\n",
      "40/46\n",
      "41/46\n",
      "42/46\n",
      "43/46\n",
      "44/46\n",
      "45/46\n",
      "46/46\n",
      "651.554775953\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "bag_of_essay1 = {}\n",
    "bag_of_essay2 = {}\n",
    "bag_of_title = {}\n",
    "count = 0\n",
    "needed = [\"project_title\", \"project_essay_1\", \"project_essay_2\", \"project_is_approved\"]\n",
    "for i in range(len(donate_table)):\n",
    "    vec = donate_table.loc[i, needed]\n",
    "    title = sentence_wrangler(vec[\"project_title\"], swords, legals)[0]\n",
    "    essay_1 = sentence_wrangler(vec[\"project_essay_1\"], swords, legals)[0]\n",
    "    essay_2 = sentence_wrangler(vec[\"project_essay_2\"], swords, legals)[0]\n",
    "    for word in title:\n",
    "        if word not in bag_of_title:\n",
    "            if vec[\"project_is_approved\"] == 1:\n",
    "                bag_of_title[word] = [0,1]\n",
    "            else:\n",
    "                bag_of_title[word] = [1,0]\n",
    "        else:\n",
    "            bag_of_title[word][vec[\"project_is_approved\"]] += 1\n",
    "    for word in essay_1:\n",
    "        if word not in bag_of_essay1:\n",
    "            if vec[\"project_is_approved\"] == 1:\n",
    "                bag_of_essay1[word] = [0,1]\n",
    "            else:\n",
    "                bag_of_essay1[word] = [1,0]\n",
    "        else:\n",
    "            bag_of_essay1[word][vec[\"project_is_approved\"]] += 1\n",
    "    for word in essay_2:\n",
    "        if word not in bag_of_essay2:\n",
    "            if vec[\"project_is_approved\"] == 1:\n",
    "                bag_of_essay2[word] = [0,1]\n",
    "            else:\n",
    "                bag_of_essay2[word] = [1,0]\n",
    "        else:\n",
    "            bag_of_essay2[word][vec[\"project_is_approved\"]] += 1\n",
    "        \n",
    "    if i%4000 == 0: \n",
    "        count += 1\n",
    "        print('%d/46' % count)\n",
    "        \n",
    "            \n",
    "end = time.time()\n",
    "print(end - start)  # roughly 6 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41222"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bag_of_essay1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'uwva', [0, 1]),\n",
       " (u'tilton', [0, 1]),\n",
       " (u'woods', [18, 89]),\n",
       " (u'spiders', [0, 5]),\n",
       " (u'hanging', [20, 75]),\n",
       " (u'localized', [0, 1]),\n",
       " (u'canes', [0, 1]),\n",
       " (u'sprague', [0, 2]),\n",
       " (u'chatter', [10, 62]),\n",
       " (u'scold', [0, 1])]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_of_essay1.items()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57497"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bag_of_essay2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'fawn', [1, 0]),\n",
       " (u'refreshable', [0, 1]),\n",
       " (u'preparesee', [0, 1]),\n",
       " (u'askew', [0, 1]),\n",
       " (u'circuitry', [20, 110]),\n",
       " (u'spiders', [3, 30]),\n",
       " (u'hanging', [48, 310]),\n",
       " (u'woody', [0, 6]),\n",
       " (u'websited', [1, 0]),\n",
       " (u'localized', [0, 1])]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_of_essay2.items()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21372"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bag_of_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'fawn', [0, 1]),\n",
       " (u'raining', [1, 19]),\n",
       " (u'writings', [0, 2]),\n",
       " (u'ekk', [0, 1]),\n",
       " (u'ncatch', [0, 1]),\n",
       " (u'nauthor', [0, 1]),\n",
       " (u'yellow', [3, 8]),\n",
       " (u'four', [6, 50]),\n",
       " (u'rocketing', [0, 4]),\n",
       " (u'woods', [4, 8])]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_of_title.items()[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>\n",
    "Generate the counts you will need for Naive Bayes\n",
    "</h2>\n",
    "<div class=h1_cell>\n",
    "<p>\n",
    "You need counts and probabilities for applications being approved or not.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class_count': (27734.0, 154346.0),\n",
       " 'class_prob': (0.1523176625659051, 0.8476823374340949),\n",
       " 'donate_count': 182080.0}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = 0.0\n",
    "classc = 0.0\n",
    "for i in range(len(donate_table)):\n",
    "    vec = donate_table.loc[i, 'project_is_approved']\n",
    "    if vec == 1:\n",
    "        classc += 1\n",
    "    count += 1\n",
    "useful_counts = {}\n",
    "useful_counts['class_count'] = (count-classc, classc)\n",
    "useful_counts['class_prob'] = ((count-classc)/count, (classc/count))\n",
    "useful_counts['donate_count'] = count\n",
    "useful_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your cosine similarity here\n",
    "def cosine_similarity(v1,v2):\n",
    "    AB = 0.0\n",
    "    A = 0.0\n",
    "    B = 0.0\n",
    "    for i in range(len(v1)):\n",
    "        AB += (v1[i] * v2[i])\n",
    "        A += (v1[i]**2)\n",
    "        B += (v2[i]**2)  \n",
    "    return AB/((A*B)**(0.5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your naive bayes here\n",
    "def naive_bayes(data, bag, counts):\n",
    "    tracker = []\n",
    "    for i in range(len(counts['class_prob'])):\n",
    "        tracker.append(counts['class_prob'][i])\n",
    "    if isinstance(data, unicode):\n",
    "        for word in sentence_wrangler(data, swords, legals)[0]:\n",
    "            if word in bag:\n",
    "                for i in range(len(counts['class_prob'])):\n",
    "                    probability = float(bag[word][i])/counts['class_count'][i]\n",
    "                    tracker[i] *= probability\n",
    "    else:\n",
    "        for word in data:\n",
    "            if word in bag:\n",
    "                for i in range(len(counts['class_prob'])):\n",
    "                    probability = float(bag[word][i])/counts['class_count'][i]\n",
    "                    tracker[i] *= probability\n",
    "    return tuple(tracker)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>\n",
    "Test your essay 1 NB\n",
    "</h2>\n",
    "<div class=h1_cell>\n",
    "<p>\n",
    "Try it for row 0. Print actual value and your predicted value.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.5539617092832785e-95, 9.791535781008517e-94)\n",
      "{'prediction': 1}\n",
      "{'actual': 1}\n"
     ]
    }
   ],
   "source": [
    "predict = naive_bayes(donate_table.loc[0, 'project_essay_1'], bag_of_essay1, useful_counts)\n",
    "p = {}\n",
    "a = {}\n",
    "if predict[0] > predict[1]:\n",
    "    p['prediction'] = 0\n",
    "else:\n",
    "    p['prediction'] = 1\n",
    "a['actual'] = donate_table.loc[0, 'project_is_approved']\n",
    "print predict\n",
    "print p\n",
    "print a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>\n",
    "Test your essay 2 NB\n",
    "</h2>\n",
    "<div class=h1_cell>\n",
    "<p>\n",
    "Try it for row 0. Print actual value and your predicted value.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2.1759687231877777e-87, 1.3477242718465147e-82)\n",
      "{'prediction': 1}\n",
      "{'actual': 1}\n"
     ]
    }
   ],
   "source": [
    "predict = naive_bayes(donate_table.loc[0, 'project_essay_2'], bag_of_essay2, useful_counts)\n",
    "p = {}\n",
    "a = {}\n",
    "if predict[0] > predict[1]:\n",
    "    p['prediction'] = 0\n",
    "else:\n",
    "    p['prediction'] = 1\n",
    "a['actual'] = donate_table.loc[0, 'project_is_approved']\n",
    "print predict\n",
    "print p\n",
    "print a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>\n",
    "Test your title NB\n",
    "</h2>\n",
    "<div class=h1_cell>\n",
    "<p>\n",
    "Try it for row 0. Print actual value and your predicted value.\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8.94705022388725e-12, 2.1026684184597748e-11)\n",
      "{'prediction': 1}\n",
      "{'actual': 1}\n"
     ]
    }
   ],
   "source": [
    "predict = naive_bayes(donate_table.loc[0, 'project_title'], bag_of_title, useful_counts)\n",
    "p = {}\n",
    "a = {}\n",
    "if predict[0] > predict[1]:\n",
    "    p['prediction'] = 0\n",
    "else:\n",
    "    p['prediction'] = 1\n",
    "a['actual'] = donate_table.loc[0, 'project_is_approved']\n",
    "print predict\n",
    "print p\n",
    "print a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999890362045437"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(bag_of_title['calm'], bag_of_title['word'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>\n",
    "Ok, the big show\n",
    "</h2>\n",
    "<div class=h1_cell>\n",
    "<p>\n",
    "Here is general strategy. Go through every row of donate_table. For each row:\n",
    "<p>\n",
    "<ol>\n",
    "<li>Transform essay 1 into a list of *unique* words.\n",
    "<li>Use Naive Bayes with that list of words and bag_of_essay1 to come up with a prediction.\n",
    "<li>Transform essay 2 into a list of *unique* words.\n",
    "<li>Use Naive Bayes with that list of words and bag_of_essay2 to come up with a prediction.\n",
    "<li>Transform title into a list of *unique* words.\n",
    "<li>Use Naive Bayes with that list of words and bag_of_title to come up with a prediction.\n",
    "<li>Store the 3 predictions as a tuple and add to all_predictions.\n",
    "</ol>\n",
    "This took me roughly 6 minutes. In the end I had a list of triples. Each triple represents the 3 votes from our experts.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'super', u'centers']\n",
      "1/46\n",
      "[u'keep', u'calm']\n",
      "[u'lets', u'3doodle']\n",
      "[u'gain']\n",
      "[u'need', u'clean', u'culinary', u'arts']\n",
      "[u'reach']\n",
      "[u'kindergartners']\n",
      "[u'fabulous', u'firsties', u'wiggling']\n",
      "[u'fidgety', u'kids', u'focus']\n",
      "[]\n",
      "[u'writing']\n",
      "[]\n",
      "[u'literacy']\n",
      "0.047455072403\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "all_predictions = []\n",
    "count = 0\n",
    "needed = [\"project_title\", \"project_essay_1\", \"project_essay_2\", \"project_is_approved\"]\n",
    "for i in range(len(donate_table)):\n",
    "    vec = donate_table.loc[i, needed]\n",
    "    title = sentence_wrangler(vec[\"project_title\"], swords, legals)[0]\n",
    "    essay_1 = sentence_wrangler(vec[\"project_essay_1\"], swords, legals)[0]\n",
    "    essay_2 = sentence_wrangler(vec[\"project_essay_2\"], swords, legals)[0]\n",
    "    \n",
    "    #get unique words\n",
    "    u_t = []\n",
    "    u_e1 = []\n",
    "    u_e2 = []\n",
    "    for word in title:\n",
    "        if word not in essay_1 and word not in essay_2 and word not in u_t:\n",
    "            u_t.append(word)\n",
    "    for word in essay_1:\n",
    "        if word not in essay_2 and word not in title and word not in u_e1:\n",
    "            u_e1.append(word)\n",
    "    for word in essay_2:\n",
    "        if word not in essay_1 and word not in title and word not in u_e2:\n",
    "            u_e2.append(word)\n",
    "    print u_t \n",
    "    #get predictions\n",
    "    t_predict = naive_bayes(u_t, bag_of_title, useful_counts)\n",
    "    if t_predict[0] >= t_predict[1]:\n",
    "        t_result = 0\n",
    "    else:\n",
    "        t_result = 1\n",
    "    e1_predict = naive_bayes(u_e1, bag_of_essay1, useful_counts)\n",
    "    if e1_predict[0] >= e1_predict[1]:\n",
    "        e1_result = 0\n",
    "    else:\n",
    "        e1_result = 1\n",
    "    e2_predict = naive_bayes(u_e2, bag_of_essay2, useful_counts)\n",
    "    if e2_predict[0] >= e2_predict[1]:\n",
    "        e2_result = 0\n",
    "    else:\n",
    "        e2_result = 1\n",
    "    results = (e1_result, e2_result, t_result)\n",
    "    if i == 12: break\n",
    "    all_predictions.append(results)\n",
    "    if i%4000 == 0: \n",
    "        count += 1\n",
    "        print('%d/46' % count)\n",
    "            \n",
    "end = time.time()\n",
    "print(end - start)  # roughly 6 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 1, 1),\n",
       " (1, 0, 1),\n",
       " (1, 1, 1),\n",
       " (1, 1, 1),\n",
       " (1, 1, 1),\n",
       " (1, 1, 1),\n",
       " (1, 1, 1),\n",
       " (1, 1, 1),\n",
       " (1, 1, 1),\n",
       " (1, 1, 1)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_predictions[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>\n",
    "Take the vote to get majority rules\n",
    "</h2>\n",
    "<div class=h1_cell>\n",
    "<p>\n",
    "\n",
    "Generate a new list combined_predictions that represents the majority vote in each triple\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_predictions = []\n",
    "for triple in all_predictions:\n",
    "    ones = 0\n",
    "    zeros = 0\n",
    "    for prediction in triple:\n",
    "        if prediction == 1:\n",
    "            ones += 1\n",
    "        else:\n",
    "            zeros += 1\n",
    "    if ones > zeros:\n",
    "        combined_predictions.append(1)\n",
    "    else:\n",
    "        combined_predictions.append(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_predictions[:10]  # should match up with majority in all_prediction triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "actuals = []\n",
    "for i in range(len(donate_table)):\n",
    "    actuals.append(donate_table.loc[i, \"project_is_approved\"])\n",
    "\n",
    "zipped = zip(combined_predictions, actuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.862197934973638"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1.0*(zipped.count((0,0)) + zipped.count((1,1)))/len(donate_table)  # trying to beat 0.8476823374340949"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(0, 0): 2887, (0, 1): 244, (1, 0): 24847, (1, 1): 154102}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_dictionary = {(1,1):0, (1,0):0, (0,1):0, (0,0):0}\n",
    "for pair in zipped:\n",
    "    confusion_dictionary[pair] += 1\n",
    "confusion_dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>\n",
    "Hmmm - nothing to write home about\n",
    "</h2>\n",
    "<div class=h1_cell>\n",
    "<p>\n",
    "The actual percentate of accepts is 0.8476823374340949. So if we just always predict 1, we will get that. We are beating that by 1 percentage point roughly. As you can see we are doing poorly with false-positives.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>\n",
    "Let's look at our experts indivually\n",
    "</h2>\n",
    "<div class=h1_cell>\n",
    "<p>\n",
    "Just take the votes of the NB for essay 1.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/46\n",
      "2/46\n",
      "3/46\n",
      "4/46\n",
      "5/46\n",
      "6/46\n",
      "7/46\n",
      "8/46\n",
      "9/46\n",
      "10/46\n",
      "11/46\n",
      "12/46\n",
      "13/46\n",
      "14/46\n",
      "15/46\n",
      "16/46\n",
      "17/46\n",
      "18/46\n",
      "19/46\n",
      "20/46\n",
      "21/46\n",
      "22/46\n",
      "23/46\n",
      "24/46\n",
      "25/46\n",
      "26/46\n",
      "27/46\n",
      "28/46\n",
      "29/46\n",
      "30/46\n",
      "31/46\n",
      "32/46\n",
      "33/46\n",
      "34/46\n",
      "35/46\n",
      "36/46\n",
      "37/46\n",
      "38/46\n",
      "39/46\n",
      "40/46\n",
      "41/46\n",
      "42/46\n",
      "43/46\n",
      "44/46\n",
      "45/46\n",
      "46/46\n"
     ]
    }
   ],
   "source": [
    "needed = [\"project_title\", \"project_essay_1\", \"project_essay_2\", \"project_is_approved\"]\n",
    "just_essay1 = []\n",
    "just_essay2 = []\n",
    "just_title = []\n",
    "count = 0\n",
    "for i in range(len(donate_table)):\n",
    "    vec = donate_table.loc[i, needed]\n",
    "    e1 = naive_bayes(vec['project_essay_1'], bag_of_essay1, useful_counts)\n",
    "    if e1[0] >= e1[1]:\n",
    "        just_essay1.append(0)\n",
    "    else:\n",
    "        just_essay1.append(1)\n",
    "    e2 = naive_bayes(vec['project_essay_2'], bag_of_essay2, useful_counts)\n",
    "    if e2[0] >= e2[1]:\n",
    "        just_essay2.append(0)\n",
    "    else:\n",
    "        just_essay2.append(1)\n",
    "    title = naive_bayes(vec['project_title'], bag_of_title, useful_counts)\n",
    "    if title[0] >= title[1]:\n",
    "        just_title.append(0)\n",
    "    else:\n",
    "        just_title.append(1)\n",
    "\n",
    "    if i%4000 == 0: \n",
    "        count += 1\n",
    "        print('%d/46' % count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8501757469244289"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zipped = zip(just_essay1, actuals)\n",
    "1.0*(zipped.count((0,0)) + zipped.count((1,1)))/len(donate_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>\n",
    "A bit worse\n",
    "</h2>\n",
    "<div class=h1_cell>\n",
    "<p>\n",
    "Just take the votes of the NB for essay 2.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.870161467486819"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zipped = zip(just_essay2, actuals)\n",
    "1.0*(zipped.count((0,0)) + zipped.count((1,1)))/len(donate_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>\n",
    "A bit better than the ensemble.\n",
    "</h2>\n",
    "<div class=h1_cell>\n",
    "<p>\n",
    "Just take the votes of the NB for title.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8570188927943762"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zipped = zip(just_title, actuals)\n",
    "1.0*(zipped.count((0,0)) + zipped.count((1,1)))/len(donate_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>\n",
    "Ok, that is not great\n",
    "</h2>\n",
    "<div class=h1_cell>\n",
    "<p>\n",
    "Have to think about whether want to include the vote for title.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>\n",
    "Closing notes\n",
    "</h2>\n",
    "<div class=h1_cell>\n",
    "<p>\n",
    "The ensemble we have put together is not very strong. Does that mean an ensemble approach won't work for this problem? I'd say the opposite. I bet it will. But not looking only at the text fields. My winter quarter data science class looked at non-text columns for use in prediction. In fact, there are a number of non-text columns that look promising, i.e., teacher_prefix,\tschool_state,\tproject_submitted_datetime,\tproject_grade_category,\tproject_subject_categories,\tproject_subject_subcategories, teacher_number_of_previously_posted_projects. I could use decision trees, a random forest or KNN to focus on some of these columns. I think I could have a very powerful ensemble if I expanded what I have with the 3 text columns: add methods that looked at more columns. Use all the info that is available to me, not just the text information.\n",
    "<p>\n",
    "The take-home message is that so far, no one machine learning method has proven to beat all others in all conditions. The ensemble approach attempts to let experts take on pieces of the problem and then combine their results. Naive Bayes is good at text analysis. Now add methods that are good with other types of columns.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
